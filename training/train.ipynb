{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d132934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from scipy import signal\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63812e4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6dafc2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BCITrainer:\n",
    "    def __init__(self, config_path='config.json'):\n",
    "        \"\"\"Initialize the BCI trainer with configuration.\"\"\"\n",
    "        self.config = self.load_config(config_path)\n",
    "        self.setup_logging()\n",
    "        \n",
    "    def load_config(self, config_path):\n",
    "        \"\"\"Load configuration from JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(config_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading config: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Set up logging configuration.\"\"\"\n",
    "        log_dir = 'logs'\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "            \n",
    "        log_file = os.path.join(log_dir, f'training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "        logging.getLogger().addHandler(file_handler)\n",
    "        \n",
    "    def load_data(self, data_path):\n",
    "        \"\"\"Load and preprocess training data.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(data_path)\n",
    "            logging.info(f\"Loaded data with shape: {df.shape}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"Preprocess the data and extract features.\"\"\"\n",
    "        # Extract features and labels\n",
    "        X = df.drop('label', axis=1)\n",
    "        y = df['label']\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(scaler, 'models/scaler.pkl')\n",
    "        \n",
    "        return X_scaled, y, scaler\n",
    "        \n",
    "    def train_model(self, X, y):\n",
    "        \"\"\"Train the model using GridSearchCV.\"\"\"\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Define parameter grid\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "        }\n",
    "        \n",
    "        # Create and train model\n",
    "        model = GridSearchCV(\n",
    "            SVC(probability=True),\n",
    "            param_grid,\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Log results\n",
    "        logging.info(f\"Best parameters: {model.best_params_}\")\n",
    "        logging.info(f\"Best cross-validation score: {model.best_score_:.3f}\")\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        logging.info(\"\\nClassification Report:\\n\" + \n",
    "                    classification_report(y_test, y_pred))\n",
    "        \n",
    "        return model, X_test, y_test\n",
    "        \n",
    "    def save_model(self, model, scaler, results_dir='models'):\n",
    "        \"\"\"Save the trained model and results.\"\"\"\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.makedirs(results_dir)\n",
    "            \n",
    "        # Save model\n",
    "        model_path = os.path.join(results_dir, 'model.pkl')\n",
    "        joblib.dump(model, model_path)\n",
    "        logging.info(f\"Model saved to {model_path}\")\n",
    "        \n",
    "        # Save results\n",
    "        results = {\n",
    "            'best_params': model.best_params_,\n",
    "            'best_score': model.best_score_,\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        results_path = os.path.join(results_dir, 'training_results.json')\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "        logging.info(f\"Results saved to {results_path}\")\n",
    "        \n",
    "    def plot_feature_importance(self, X, feature_names):\n",
    "        \"\"\"Plot feature importance.\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        importances = np.abs(np.corrcoef(X.T, y)[:-1, -1])\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.title('Feature Importance')\n",
    "        plt.bar(range(len(importances)), importances[indices])\n",
    "        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('models/feature_importance.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def plot_confusion_matrix(self, y_true, y_pred):\n",
    "        \"\"\"Plot confusion matrix.\"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig('models/confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def plot_roc_curve(self, y_true, y_pred_proba):\n",
    "        \"\"\"Plot ROC curve.\"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig('models/roc_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def plot_learning_curve(self, model, X, y):\n",
    "        \"\"\"Plot learning curve.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            model, X, y, cv=5, n_jobs=-1, \n",
    "            train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "        \n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        test_mean = np.mean(test_scores, axis=1)\n",
    "        test_std = np.std(test_scores, axis=1)\n",
    "        \n",
    "        plt.plot(train_sizes, train_mean, label='Training score')\n",
    "        plt.plot(train_sizes, test_mean, label='Cross-validation score')\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, \n",
    "                        train_mean + train_std, alpha=0.1)\n",
    "        plt.fill_between(train_sizes, test_mean - test_std, \n",
    "                        test_mean + test_std, alpha=0.1)\n",
    "        plt.xlabel('Training Examples')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title('Learning Curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('models/learning_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def run_training(self, data_path):\n",
    "        \"\"\"Run the complete training pipeline.\"\"\"\n",
    "        try:\n",
    "            # Load and preprocess data\n",
    "            df = self.load_data(data_path)\n",
    "            X, y, scaler = self.preprocess_data(df)\n",
    "            \n",
    "            # Train model\n",
    "            model, X_test, y_test = self.train_model(X, y)\n",
    "            \n",
    "            # Generate predictions\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Save model and results\n",
    "            self.save_model(model, scaler)\n",
    "            \n",
    "            # Create plots\n",
    "            self.plot_feature_importance(X, df.columns[:-1])\n",
    "            self.plot_confusion_matrix(y_test, y_pred)\n",
    "            self.plot_roc_curve(y_test, y_pred_proba)\n",
    "            self.plot_learning_curve(model, X, y)\n",
    "            \n",
    "            logging.info(\"Training completed successfully\")\n",
    "            return model, scaler\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in training pipeline: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b57717",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    trainer = BCITrainer()\n",
    "    model, scaler = trainer.run_training('data/training_data.csv') "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
